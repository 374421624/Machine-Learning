# 参数范数惩罚

许多正则化方法通过对目标函数 $$J$$ 添加一个参数范数惩罚 $$\Omega(\theta)$$，限制模型的学习能力。我们将正则化后的目标函数记为 $$\tilde{J}$$ ：

                                                        $$\tilde{J}(\theta;X,y)=J(\theta;X,y)+\alpha\Omega(\theta)$$ 

其中 $$\alpha\in[0,\infty)$$ 是权衡范数惩罚项 $$\Omega$$ 和标准目标函数 $$J(X;\theta)$$ 相对贡献的超参数。将 $$\alpha$$ 设为 $$0$$ 表示没有正则化。 $$\alpha$$ 越大，对应正则化惩罚越大。

## $$L^2$$ 正则化

## $$L^1$$ 正则化

