# 参数范数惩罚

许多正则化方法通过对目标函数 $$J$$ 添加一个参数范数惩罚 $$\Omega(\theta)$$，限制模型的学习能力。我们将正则化后的目标函数记为 $$\tilde{J}$$ ：

                                                        $$\tilde{J}(\theta;X,y)=J(\theta;X,y)+\alpha\Omega(\theta)$$ 

其中 $$\alpha\in[0,\infty)$$ 是权衡范数惩罚项 $$\Omega$$ 和标准目标函数 $$J(X;\theta)$$ 相对贡献的超参数。将 $$\alpha$$ 设为 $$0$$ 表示没有正则化。 $$\alpha$$ 越大，对应正则化惩罚越大。

## $$L^2$$ 正则化

这个正则化策略通过向目标函数添加一个正则项 $$\Omega(\theta)=\frac{1}{2}||w||^2_2$$ ，使权重更加接近原点。在其他学术圈， $$L^2$$ 也被称为岭回归或Tikhonov正则。DNN的 $$L^2$$ 正则化通常的做法是只针对与线性系数矩阵 $$w$$ ,而不针对偏倚系数 $$b$$ 。我们很容易可以写出DNN的 $$L^2$$ 正则化的损失函数：

                             $$\tilde{J}(w;X,y)=J(w;X,y)+\frac{\alpha}{2}||w||^2_2=J(w;X,y)+\frac{\alpha}{2}w^Tw$$ 

与之对应的梯度为

                                                $$\nabla_w\tilde{J}(w;X,y)=\nabla _wJ(w;X,y)+\alpha w$$ 

使用单步梯度下降更新权重，即执行以下更新

                                                    $$w\gets w-\epsilon(\alpha w+\nabla_wJ(w;X,y))$$ 

                                               $$= w\gets (1-\epsilon \alpha)w-\epsilon\nabla_wJ(w;X,y)$$ 

通过上式我们可以看出，加入权重衰减后会引起学习规则的修改。即在每步执行通常的梯度更新之前先收缩权重向量\( $$(1-\epsilon \alpha)w$$ 将权重向量乘以一个常数因子\)。这是单个步骤发生的变化。我们进一步简化分析，令 $$w^*$$ 为未正则化的目标函数取得最小训练误差时的权重向量，即 $$w^* = \mathop{\arg\min}\limits_wJ(w)$$ ，并在 $$w^*$$ 的邻域对目标函数做二次近似。如果目标函数确实是二次的（如以均方差拟合线性回归模型的情况），则该近似是完美的。近似的 $$\tilde{J}(\theta)$$ 如下

                                            $$\tilde{J}(\theta)=J(w^*)+\frac{1}{2}(w-w^*)^TH(w-w^*)$$ 

其中 $$H$$ 是 $$J$$ 在 $$w^*$$ 处计算的Hessian矩阵（关于 $$w$$ ）。因为 $$w^*$$ 被定义为最优，即梯度消失为 $$0$$ ，所以该二次近似中没有一阶项。同样地，因为 $$w^*$$ 是 $$J$$ 的一个最优点，我们可以得出 $$H$$ 是半正定的结论。

## $$L^1$$ 正则化

