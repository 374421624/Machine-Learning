# 特征选择

我们能用很多属性描述一个西瓜，例如色泽、根蒂、敲声、纹理等，但有经验的恶人往往只看根蒂、听听敲声就知道是否好瓜。换言之，对一个学习任务来说，给定属性集，其中有些属性可能很关键、很有用，另一些属性则可能没什么用。我们将属性称为“特征”，对当前学习任务有用的属性称为“相关特征”、没什么用的属性称为“无关特征”。从给定的特征集合中选择出相关特征子集的过程，称为“特征选择”。

进行“特征选择”有两个重要原因：

（1）我们在现实任务中经常会遇到维数灾难问题，这是由于属性过多而造成的，若能从中选择出重要的特征，使得后续学习过程仅需一部分特征上构建模型，则维数灾难问题会大为减轻。

（2）去除不相关特征往往会降低学习任务的难度，这就像侦探破案一样，若将纷繁复杂的因素抽丝剥茧，只留下关键因素，则真相往往更易看清。

## 子集搜索与评价

特征选择过程必须确保不丢失重要特征，否则后续学习过程会因为重要信息的缺失而无法获得好的性能。欲从初始的特征集合中选取一个包含了所有重要信息的特征子集，若没有任何领域知识作为先验假设，那就只好遍历所有可能的子集了；然而这在计算上却是不可行的，因为这样会遭遇组合爆炸，特征个数稍微多就无法进行了。可行的做法是产生一个“候选子集”，评价出它的好坏，基于评价结果产生下一个候选子集，再对其进行评价。这个过程持续下去，直至无法找到更好的候选子集为止。这里涉及两个关键环节：（1）如何根据评价结果获取下一个候选特征子集 （2）如何评价候选子集的好坏

### 子集搜索

给定特征集合 $$\{a_1,a_2,\dots,a_d\}$$ ，我们可将每个特征看作一个候选子集，对这 $$d$$ 个候选单特正子集进行评价，假定 $$\{a_2\}$$ 最优，于是将 $$\{a_2\}$$ 作为第一轮的候选集。

### 子集评价

## 过滤式选择

## 包裹式选择

## 嵌入式选择与 $$L_1$$ 正则化

## 系数表示与字典学习

## 压缩感知

