# 标签传播

标签体系是各大公司业务系统最重要的基石，无论是user标签还是item标签，无论多模态文本标签、图片标签还是视频标签。可以这样说，评价一个公司技术能力强弱，其构建起的标签体系是最关键的评价指标。这里基于个人经验，借鉴GNetMine以及PageRank算法，阐述自己设计的基于社交图谱的标签传播算法。

标签体系最基础也是最难的两个目标，就是准和全。准即准确率，要求算法打的标签要准确，毕竟标签体系很大一部分是作为其他后续算法的输入，如果后续算法的数据源都不准确，何谈产出好效果；全即覆盖率，要求覆盖一定量数据集，如果数据集很少那人工打标即可，还特别准，然而现实业务场景应用中，数据集非常大，人工只能打标其中一部分，这就要求算法要具有一般性。这里我利用知识图谱的信息传递性，尤其社交网络中的关系传递，只用约万分之一的已标注样本量给大量待标注数据进行标签标注\(约十万已标注数据给数十亿数据打标\)，且效果准确，可用于商业推广。

## 算法概述

基于约十万已标注账号信息，一段时间内账号间社交互动\(关注、转发、评论等\)信息，输出预测未标注账号属于各类别概率，设计了基于社交网络的多轮迭代标签传播算法。分为损失设计、标签传播、结果汇集三部分解释。总流程如下：

```text
初始化: f(0)=y, Loss(0)=Inf

while Loss变小:
    标签传播: 由第t-1轮结果f(t-1)和社交互动关系R，得到第t轮结果f(t)
    结果汇集: 基于第t轮结果f(t)汇集成p(t)
    损失计算: 基于p(t)计算Loss(t)

输出Loss最小一轮结果p
```

## 算法设计

### 损失函数

损失如下公式，由精度损失和泛化损失两部分组成，其中 $$\alpha$$和 $$\beta$$ 调节更关注准确还是泛化：

                             $$\text{Loss}=\alpha\sum\limits_{i=1}^I\sigma_i|\hat{y_i}-y_i|+\beta\sum\limits_{a,b}^S\omega_{a,b}|\hat{y_a}-\hat{y_b}|\\  =\alpha \sum\limits_{i=1}^I\sigma_i|\cos(\hat{p(t)_i},y_i)|+\beta\sum\limits_{a,b}^S\omega_{a,b}|\cos(\hat{p(t)_a},\hat{p(t)_b})|$$ 

1、精度损失 $$\alpha \sum\limits_{i=1}^I\sigma_i|\cos(\hat{p(t)_i},y_i)|$$ 。集合 $$I$$ 为Ground Truth集合；参数 $$\sigma_i$$ 表示 $$i$$ 个已标注样本账号的重要程度，比如在微博场景下是此账号的粉丝数等，我们更倾向于将粉丝量大的账号类别预测准；余弦距离 $$|\cos(\hat{p(t)_i},y_i)|$$ 即第 $$t$$ 轮账号 $$i$$ 的预测向量和其Ground Truth向量的余弦距离，向量每一列对应一个类别，比如分成语数外三类， $$\hat{p(t)_i}=(0.2,0.7,0.1)$$ ，账号 $$y_i=(0,1,0)$$ 实际属于数学类别。

2、泛化损失 $$\beta\sum\limits_{a,b}^S\omega_{a,b}|\cos(\hat{p(t)_a},\hat{p(t)_b})|$$ 。集合 $$S$$ 为相似账号的集合；参数 $$w_{a,b}$$ 表示账号 $$a$$ 和 $$b$$ 的相似程度，比如微博场景下粉丝重合度 $$w_{a,b}=\frac{A\cap B}{A\cup B}$$ ，两账号粉丝交集数/两账号粉丝并集数，我们更倾向于关注粉丝重合度高的账号对，物理意义即若两账号粉丝相同，则两账号类别大概率相似；余弦距离 $$|\cos(\hat{p(t)_a},\hat{p(t)_b})|$$ 即第 $$t$$ 轮账号 $$a$$ 的预测向量和第 $$t$$ 轮账号 $$b$$ 的预测向量的余弦距离。

### 标签传播

具体标签传播过程可以由下面公式表达，第t+1轮结果由第t轮结果进行传播加Ground Truth：

                                         $$f(t+1)=\sum\limits_{r\in R} W_r*f(t)+W_y*y \\ =\sum\limits_{r\in R} (\alpha_r*P_r*Q_r)*f(t)+W_y*y$$ 

1、标签传播 $$\sum\limits_{r\in R} (\alpha_r*P_r*Q_r)*f(t)$$ 。集合 $$R$$ 为社交互动类型集合，比如 $$R = \{关注、转发、评论\}$$ ， $$r$$ 即其中一种互动类型； $$\alpha_r$$ 即互动类型 $$r$$ 的影响因子，比如微博场景下关注、转发、评论的社交成本是不一样的，转发的少，而评论和关注次之，而大家经常随意点赞，这个因子是调节不同社交互动的融合权重； $$P_r$$ 和 $$Q_r$$ 为账号影响力矩阵和活跃度矩阵，一百万个粉丝的账号和一万个粉丝的账号影响力不同，一周关注一千个人和一周关注十个人的活跃度不同，这两个矩阵进行权重调节； $$f(t)$$ 即第 $$t$$ 轮结果，若 $$M$$ 个账号分为 $$N$$ 类，则 $$f(t)$$是一个 $$M*N$$ 的矩阵，第 $$m$$ 行第 $$n$$ 列即代表账号 $$m$$ 属于第 $$n$$ 类的权值，其中第0轮结果 $$f(0)=y$$ ，即假设有 $$K$$个已标注账号， $$f(0)$$ 的这 $$K$$ 行对应的第 $$n$$ 列为 $$1$$ ，其他为 $$0$$ ，剩下的 $$M-K$$ 行全为0。

2、加入Ground Truth， $$W_y*y$$ 。每轮结果再加入Ground Truth， $$W_y$$ 为行业及账号权重调节，比如微博场景下，文娱和金融和教育几个类别量级是不一样的，这里做标准化； $$y$$ 即Ground Truth的矩阵。

### 结果汇集

获得第 $$t$$ 轮的结果 $$f(t)$$ 后，根据关系对聚合成对应账号的结果向量：

                                                        $$p(t)_x=\sigma(\sum\limits_{a}^Af(t)_a)$$ 

账号 $$x$$ 结果通过其粉丝集合 $$A$$求和，然后经过标准化得到，标准化 $$\sigma$$ 任选，比如softmax。

## 算法解释

**标签传播：**算法下一轮结果 $$f(t +1)$$ 都由当前轮结果 $$f(t)$$ 进行标签传播再加Ground Truth $$y$$ ，可以想象为农田水渠灌溉，每轮加Ground Truth就像水源头，标签传播就像水流随着水渠流动，只不过算法中是类别权重按照社交互动行为进行流动。

**多跳传播：**第 $$t$$ 轮，会进行 $$1\dots t$$ 跳传播，例如 $$t = 1$$ 时，只有 $$1$$ 跳传播，已标注账号的信息传播至与其进行过社交互动的账号；当 $$t = 2$$ 时，已标注账号的信息依旧传播至与其进行过社交互动的账号\( $$1$$ 跳\)，此时上一轮通过1跳得到信息的账号，在这一轮将信息传给了与他互动的账号，即已标注账号信息通过1跳媒介又将信息传播了出去\( $$2$$ 跳\)...

**Loss表现：**1、对于精度损失\(已标注账号和其预估结果\)，每个账号的 $$n$$ 维向量 $$p(t)_x$$ 是由其粉丝向量聚合得到，已标注账号 $$x$$ 的标签传给其粉丝，粉丝又将标签汇集给已标注账号 $$x$$ ；对于泛化损失\(粉丝相同两账号分类应相似\)，粉丝重合越高，两账号 $$a$$ 和 $$b$$ 越相似，获得的 $$n$$ 维向量 $$p(t)_a$$ 和 $$p(t)_b$$ 由粉丝向量聚合得到，所以也会约接近。随着轮数越来越多，标签传播hop增多，噪声干扰会越来越多，会导致Loss上升。所以模型经多轮计算，Loss逐渐下降，待到开始上升时停止迭代，输出Loss最小轮时所生成的结果。

**应用方式：**算法最后得出的是一个 $$M*N$$ 维的矩阵，其中 $$M$$ 是账号数，每个账号对应一行， $$N$$ 是类别数，第 $$n$$ 列的值为属于这个类别的权值。所以，一个账号对应一个可解释的 $$N$$ 维向量。

* 这个 $$N$$ 维向量可以作为后续算法的输入，为匹配，点击等等模型提供源数据...
* 打破自然与广告间gap，一个娱乐搞笑账号，投什么行业广告比较好，它的 $$N$$ 维向量告诉你...
* 通过计算向量间余弦距离，获得相似账号，进行账号聚类，Lookalike扩充...
* 生成的结果会有异常账号，比如 $$N$$ 维全0但查看其页面粉丝量还挺高，这就是甄别刷僵尸号的方法...

